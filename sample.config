model = 'model_name'
source_train = 'path to train file of source side.'
target_train = 'path to train file of target side.'
source_dev = 'path to development file.'
source_test = 'path to test file.'

method = 'shared_target' [separated_source / separated_target / shared_source / shared_target / shared_mix]

use_train_gpu = True [True or False]
use_dev_gpu = True [True or False]
use_test_gpu = True [True or False]
gpu_device = 0

word2vec_method = "Make" [Make / Load / None]
word2vec_window_size = 5
source_word2vec_file = 'path to word2vec file of source side'
target_word2vec_file = 'path to word2vec file of target side'

vocabulary_method = "Make" [Make / Load]
source_vocabulary_file = 'path to vocabulary file of source side'
target_vocabulary_file = 'path to vocabulary file of source side'

bilstm_method = "FinalAdd"
attention_method = "LuongDot"
activation_method = "tanh"

epoch = 30
optimizer = "Adam"
learning_rate = 0.01
clipping_threshold = 5
train_batch_size = 32
dev_batch_size = 128
test_batch_size = 1  
pooling_size = 1000
data_saving_directory = './training_data'

use_pretrain = False
pretrain_epoch = 29

layer_size = 2
source_vocabulary_size = 40000
target_vocabulary_size = 40000
embed_size = 512
hidden_size = 512
use_dropout = True
dropout_rate = 0.2
use_residual = False

generation_limit = 100
use_beamsearch = True
beam_size = 5
make_log = True 
